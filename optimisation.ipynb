
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "[![Script](https://acm.im/bristlecone//img/badge-script.svg)](https://acm.im/bristlecone//optimisation.fsx)\u0026emsp;\n",
    "[![Notebook](https://acm.im/bristlecone//img/badge-notebook.svg)](https://acm.im/bristlecone//optimisation.ipynb)\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": null, "outputs": [],
   "source": [
    "#r \"nuget: Bristlecone,3.0.0-beta1\"\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "# Optimisation Methods\n",
    "\n",
    "Bristlecone includes a suite of in-built local and global\n",
    "optimisation methods. You can also use a custom optimisation\n",
    "method defined in another library, or combine these with the\n",
    "in-built optimisation techniques.\n",
    "\n",
    "## Defining a custom optimisation method\n",
    "\n",
    "A custom optimisation\n",
    "procedure can be used with Bristlecone by plugging in as follows:\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 2, "outputs": [],
   "source": [
    "open Bristlecone\n",
    "\n",
    "let myCustomOptimiser: EstimationEngine.Optimisation.Optimiser =\n",
    "    EstimationEngine.Optimisation.InDetachedSpace\n",
    "    \u003c| fun writeOut n domain f -\u003e invalidOp \"Doesn\u0027t actually do anything!\"\n",
    "\n",
    "Bristlecone.mkContinuous ()\n",
    "|\u003e Bristlecone.withCustomOptimisation myCustomOptimiser\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "## Included optimisation methods\n",
    "\n",
    "The library itself includes Monte Carlo-based methods, and Amoeba (Nelder Mead Simplex) methods.\n",
    "All methods are included in this namespace:\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 3, "outputs": [],
   "source": [
    "open Bristlecone.Optimisation\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "### Simulated Annealing (SA)\n",
    "\n",
    "Simulated annealing models a minimisation problem in terms of particle\n",
    "entropy, where the function value is analogous to energy. At high\n",
    "temperatures, particles are in a high-energy state, thus can move\n",
    "readily. As temperature gradually decreases, particles are less able\n",
    "to move to high energy states, with particles eventually arranging\n",
    "into the ‘ground state’ of a solid material.\n",
    "\n",
    "The SA implementation in Bristlecone includes classical SA that uses\n",
    "a Boltzmann machine for jumps, and fast simulated annealing (FSA) that\n",
    "uses a Cauchy distribution for jumps:\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 4, "outputs": [],
   "source": [
    "let settings = MonteCarlo.SimulatedAnnealing.AnnealSettings.Default\n",
    "\n",
    "// Classical Simulated Annealing:\n",
    "MonteCarlo.SimulatedAnnealing.classicalSimulatedAnnealing 0.01\u003c``optim-space``\u003e false settings\n",
    "\n",
    "// Fast Simulated Annealing:\n",
    "MonteCarlo.SimulatedAnnealing.fastSimulatedAnnealing 0.01\u003c``optim-space``\u003e false settings\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "The FSA approach enables greater exploration of more distant portions of\n",
    "parameter space more quickly and is therefore less prone to local minima\n",
    "problems.\n",
    "\n",
    "For the SA implementation in Bristlecone, you must specify whether you\n",
    "wish to use a temperature-dependent or temperature-independent proposal.\n",
    "When temperature-dependent, the jump size increases at higher temperatures,\n",
    "allowing coarser exploration of the parameter space initially, progressively\n",
    "becoming more refined as the system cools.\n",
    "\n",
    "### Nelder-Mead Methods\n",
    "\n",
    "The Nelder-Mead simplex (or amoeba method) expands and contracts an n-dimensional\n",
    "geometry within an unconstrained parameter space, following a\n",
    "‘downhill’ gradient. The implementation here draws a random point from a\n",
    "normal distribution, informed by the starting bounds for each parameter.\n",
    "\n",
    "The Nelder-Mead simplex is most appropriate for simpler likelihood surfaces.\n",
    "It can be used as follows:\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 5, "outputs": [
          {
           "data": {
            "text/plain": ["{ Alpha = 1.0",
"  Sigma = 0.5",
"  Gamma = 2.0",
"  Rho = 0.5",
"  Size = 3 }"]
        },
           "execution_count": 5,
           "metadata": {},
           "output_type": "execute_result"
          }],
   "source": [
    "let settingsNM = Amoeba.Solver.Default\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 7, "outputs": [],
   "source": [
    "let single: EstimationEngine.Optimisation.Optimise = Amoeba.Solver.solve settingsNM\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "A single Nelder-Mead solver is highly subject to local minima. To reduce\n",
    "the prevalence of local minima, Bristlecone includes a **swarm** implementation\n",
    "of the Nelder-Mead simplex, which, creates an ensemble of 20 amoeba, all of which\n",
    "crawl the likelihood surface. After n iterations, all amoeba that have values\n",
    "above the 80th percentile of the negative log likelihood values are\n",
    "discarded. The procedure continues for five levels. The swarm mode\n",
    "can be used from:\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 8, "outputs": [],
   "source": [
    "let levels = 5\n",
    "let individuals = 20\n",
    "\n",
    "Amoeba.swarm levels individuals settingsNM\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "### Monte Carlo methods\n",
    "\n",
    "Monte Carlo Markov Chain (MCMC) methods are most often applied in Bayesian\n",
    "analyses, but can also be used for optimisation to identify the -log likelihood.\n",
    "Within Bristlecone, a number of variations of Monte Carlo methods are included.\n",
    "\n",
    "Often, it is appropriate to use multiple methods in combination; initially, tuning\n",
    "algorithm(s) are used to enhance the performance of the search. Once the tuning phase\n",
    "is complete, a search is conducted to identify the minimum; finally, a sampling algorithm\n",
    "may be run to explore the distribution around the minimum.\n",
    "\n",
    "#### Random Walk Metropolis Hastings\n",
    "\n",
    "The random walk algorithm may optionally be passed a list of `TuningStep`s,\n",
    "which will be run before the final random walk.\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 9, "outputs": [],
   "source": [
    "open Bristlecone.Optimisation.MonteCarlo\n",
    "\n",
    "// Random walk with no tuning steps\n",
    "MonteCarlo.randomWalk []\n",
    "\n",
    "// Random walk with 50,000 iterations of tuning, during\n",
    "// which the individual parameter jump sizes are scaled\n",
    "// every 500 iterations.\n",
    "[ { Method = MonteCarlo.TuneMethod.Scale\n",
    "    Frequency = 500\u003citeration\u003e\n",
    "    EndCondition = EndConditions.atIteration 50000\u003citeration\u003e } ]\n",
    "|\u003e MonteCarlo.randomWalk\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "#### Adaptive Metropolis (AM)\n",
    "\n",
    "The AM algorithm continuously tunes the covariance structure of the\n",
    "jump distribution based on the size of jumps in the recently-explored\n",
    "parameter space.\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 10, "outputs": [],
   "source": [
    "let weighting = 0.250 // Weight to give to recent history versus existing covariance structure\n",
    "let frequency = 200\u003citeration\u003e // Tune the covariance structure every 200 iterations\n",
    "\n",
    "MonteCarlo.adaptiveMetropolis weighting frequency\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "#### Filzbach-style Monte Carlo\n",
    "\n",
    "The Filzbach algorithm was introduced by Drew Purves, Microsoft Research\n",
    "Cambridge. The Filzbach algorithm was designed for problems in ecological\n",
    "research. It contains a burn-in phase and a sampling phase.\n",
    "Four settings are required: the length of the burn-in phase (which can be\n",
    "any Bristlecone `EndCondition`); the minimum and maximum scale changes that can\n",
    "occur within the tuning phase, based on the ranges given for each parameter in\n",
    "the model definition; and the number of changes after which to conduct parameter\n",
    "tuning.\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 11, "outputs": [],
   "source": [
    "open Bristlecone.Optimisation.MonteCarlo.Filzbach\n",
    "\n",
    "let settingsFB =\n",
    "    { TuneAfterChanges = 20\n",
    "      MaxScaleChange = 100.\n",
    "      MinScaleChange = 0.01\n",
    "      BurnLength = EndConditions.atIteration 100000\u003citeration\u003e }\n",
    "\n",
    "filzbach settingsFB\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "#### \u0027Automatic\u0027 optimisation\n",
    "\n",
    "Implementation similar to that proposed by Yang and Rosenthal: \"Automatically Tuned\n",
    "General-Purpose MCMC via New Adaptive Diagnostics\"\n",
    "[Reference](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.70.7198\u0026rep=rep1\u0026type=pdf)\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 12, "outputs": [],
   "source": [
    "MonteCarlo.``Automatic (Adaptive Diagnostics)``\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "#### Adaptive-Metropolis-within Gibbs\n",
    "\n",
    "An adaptive Metropolis-within-Gibbs sampler that tunes the variance of\n",
    "each parameter according to the per-parameter acceptance rate.\n",
    "Reference: Bai Y (2009). “An Adaptive Directional Metropolis-within-Gibbs Algorithm.”\n",
    "Technical Report in Department of Statistics at the University of Toronto.\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 13, "outputs": [],
   "source": [
    "MonteCarlo.``Adaptive-Metropolis-within Gibbs``\n"
   ]
  }
,
  {
   "cell_type": "markdown",
   "metadata": {},
   
   "source": [
    "#### Metropolis-within Gibbs\n",
    "\n",
    "A non-adaptive Metropolis-within-gibbs Sampler. Each parameter\n",
    "is updated individually, unlike the random walk algorithm.\n",
    "\n"
   ]
  }
,
  {
   "cell_type": "code",
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "execution_count": 14, "outputs": [],
   "source": [
    "MonteCarlo.``Metropolis-within Gibbs``\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (F#)",
   "language": "F#",
   "name": ".net-fsharp"
  },
  "language_info": {
   "file_extension": ".fs",
   "mimetype": "text/x-fsharp",
   "name": "polyglot-notebook",
   "pygments_lexer": "fsharp"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "fsharp",
    "items": [
     {
      "aliases": [],
      "languageName": "fsharp",
      "name": "fsharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

